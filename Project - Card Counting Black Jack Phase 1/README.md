# Project 1 - Card Counting Black Jack: Phase 1

## ğŸ“‹ Description

In this project, you will try to find an optimal Black Jack policy that also attempts to use card counting to beat the dealer in a single-player game (your agent vs. the dealer).

---

## ğŸƒ Basic Blackjack Setup

The game rules are:

- A standard 52-card deck is used (cards 1â€“10, J, Q, K across four suits).
- You and the dealer are both dealt two cards:
  - One of the dealer's cards is hidden.
- You can choose to:
  - **STAY** with your current hand
  - **DRAW** another card (repeatable until bust, win, or stay)

### Game Outcomes

- If your sum exceeds 21 â†’ **Lose (-1)**
- If your sum equals 21 â†’ **Win (+1)**
- If you choose to stay < 21, the dealer:
  - Reveals their hidden card
  - Wins if sum = 21
  - Draws if sum â‰¤ 16
  - Stays if 17 â‰¤ sum â‰¤ 20
  - If dealer busts (>21) â†’ **You win**
  - Higher sum wins; tie = **Draw (0)**

### Special Rule

- Aces can count as **1 or 11**, whichever is more beneficial.

> ğŸ’¡ No card splitting or betting mechanics are implemented.

---

## ğŸ§ª Task 0 â€“ Basic Game Setup

- Implement a basic interactive or visual Blackjack game environment.
- Allow either a human or an RL agent to play against the dealer.
- Visualization can be via simple print statements or a basic GUI.

---

## ğŸ¤– Task 1 â€“ Tabular Q-Learning Agent

Train an agent using tabular Q-learning to learn the optimal policy for:
- When to **STAY**
- When to **DRAW**

### ğŸ” Subtasks

#### 1.1: Play a few games against the dealer

- Evaluate the **win percentage** achieved by your trained agent.

#### 1.2: Prove the optimal policy

- If your agent has found an optimal policy, show evidence.
- Report the **expected best win %**:
  - If **< 50%**, youâ€™ll lose money on average.
  - If **> 50%**, youâ€™re **beating the casino**.

---

## ğŸ§  Task 2 â€“ Card Counting Agent (Hi-Lo)

Now improve your agentâ€™s win rate using basic card counting with the Hi-Lo system.

### ğŸƒ Hi-Lo Count Rules

- Cards **2â€“6** â†’ +1
- Cards **7â€“9** â†’ 0
- Cards **10â€“Ace** â†’ -1

### Mechanics

- Use a **single deck** of 52 cards.
- Discarded cards remain out until:
  - Fewer than 10 cards remain â†’ reshuffle deck.

### ğŸ”¢ Count State Categories

Use the running count as an extra state feature:
- **High**: Count > +5
- **Neutral**: -5 â‰¤ Count â‰¤ +5
- **Low**: Count < -5

Train a new tabular Q-learning agent with this extra state dimension.

### â“ Questions to Answer

- Does the card-counting agent perform better than the Task 1 agent?
- What is the **best average win %** with the new agent?
  - If **> 50%**, you can consistently beat the casino!

---

## ğŸ“Œ Remarks

- You may optionally explore:
  - Monte Carlo control
  - Policy Iteration / Value Iteration
- If using PI/VI:
  - Calculate transition probabilities (easier than expected, consider Markov Chains)
- Thresholds **(+5, -5)** may be rare in one-deck scenariosâ€”consider experimenting with tighter thresholds.

---

## ğŸ”— References

- [How to Play Blackjack â€“ Bicycle Cards](https://bicyclecards.com/how-to-play/blackjack)

---

> ğŸ§  Good luck exploring the math and strategy behind Blackjack!
